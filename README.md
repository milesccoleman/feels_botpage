<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-67390232-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-67390232-4');
</script>
# feels_bot

This interactive exhibit uses artificial intelligence, emotionally potent sounds, and a connection to all of the .gifs on the internet to give a glimpse into what it might be like if a machine could "catch feels." The exhibit emphasizes the material, nonverbal, and affective dimensions of communication by responding emotionally to keyboard input from the user. Understandably, the bot reacts in ways different from our normal human-to-human communication.

Users are encouraged to think about empathy, intentionality, and genuine connection. Do we (humans) communicate like machines? Should we? 

<iframe src="https://milesccoleman.com/feels_bot/#/" width="800" height="1000"></iframe>


Click [here](https://github.com/milesccoleman/feels_bot) to access the code for feels_bot. 
